| **Проект**  | **Описание**  |
|:---------- |:---------------|
|[1. Прогнозирование продаж компьютерных игр](https://github.com/mamban1997/educational-projects/blob/main/%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D1%8B/Forecasting%20sales%20of%20computer%20games.ipynb "Перейти")| По данным продаж компьютерных игр до 2016 года включительно необходимо выявить закономерности успешности игр, чтобы спланировать рекламную компанию на 2017 год. Так-же необходимо составить игровой портрет пользователей из разных регионов и проверить несколько гипотез. При помощи графиков и сводных таблиц были выбраны наиболее популярные платформы и жанры во всем мире и в каждом регионе. При помощи стат-тестов были были проверены гипотезы о том, что средние рейтинги игр на платформах PC и XOne одинаковые и том, что жанры sports и action имеют разные оценки пользователей. Стек: pandas, numpy, matplotlib и scipy. |
| [2. Определение стоимости автомобилей](https://github.com/mamban1997/educational-projects/blob/main/%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D1%8B/Determining%20the%20cost%20of%20cars.ipynb "Перейти")| По историческим данным цен, технических характеристик и комплектации автомобилей необходимо предсказать их стоимость. После очистки датасета от пропусков и аномалий был применен градиентный бустинг lightgbm. Среднеквадратичная ошибка модели оказалась 1684$, а предсказание средним дает разброс 4669$. Самыми влияющими факторами на цену автомобиля оказались мощность двигателя и год его выпуска. Стек: pandas, numpy, matplotlib, sklearn, lightgbm   |
|[3. Классификация позитивных и негативных комментариев.](https://github.com/mamban1997/educational-projects/blob/main/%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D1%8B/Classification%20of%20positive%20and%20negative%20comments.ipynb "Перейти")| При помощи машинного обучения необходимо классифицировать комментарии на позитивные и негативные.Задача была решена 2мя способами. Первый - корпус текстов был лемматизирован и векторизован (TF-IDF), предсказание осуществлялось логистической регрессией. Второй - корпус текстов был токенизирован и при помощи предобученной модели BERT из него были выделены ембендинги фраз. Предсказание также осуществлялось логистической регрессией. Лучший результат на тестовой выборке F1_score - 0,77. Стек: pandas, numpy, sklearn, lightgbm, NLTK, BERT(transformers и PyTorch )    |
| [4. Прогнозирование восстановления золота](https://github.com/mamban1997/educational-projects/blob/main/%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D1%8B/Forecasting%20gold%20recovery.ipynb "Перейти") | По предоставленным данным о параметрах сырья на различных этапах обогащения необходимо предсказать коэффициент восстановления золота из золотосодержащей руды. Итоговая метрика - smape.  Ошибка модели - 7,15%.       |


